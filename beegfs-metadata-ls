#!/usr/bin/env python3

import sys, os, stat, argparse, re, itertools, collections
from collections import defaultdict, namedtuple
from pathlib import Path

Dir = namedtuple("Dir", ["name", "tag", "meta", "nosub"], defaults=["", "", "", False])
File = namedtuple(
    "File",
    ["dirs", "name", "tag", "chunks", "empty", "meta"],
    defaults=[[], "", "", [], False, ""],
)
FileChunk = namedtuple("FileChunk", ["file", "chunks"], defaults=[File(), []])

args = None


def parse_args():
    global args
    parser = argparse.ArgumentParser()
    parser.add_argument("-v", "--verbose", action="store_true")
    parser.add_argument("-q", "--quiet", action="store_true")
    parser.add_argument("-f", "--list-files", action="store_true")
    parser.add_argument("-d", "--list-directories", action="store_true")
    parser.add_argument("-c", "--list-chunks", action="store_true")
    parser.add_argument("-s", "--script", action="store_true")
    parser.add_argument("-e", "--empty-directories", action="store_true")
    parser.add_argument("-m", "--missing-chunks", action="store_true")
    parser.add_argument("-t", "--tags", action="store_true")
    parser.add_argument("-n", "--max-files", type=int)
    parser.add_argument("-u", "--user", default="")
    parser.add_argument("-o", "--output")
    parser.add_argument("-C", "--command", default="cp -pi")
    parser.add_argument("-D", "--dest-dir", default="")
    parser.add_argument("dir", nargs="?", default=".")
    args = parser.parse_args()


def err(*fargs, **fkwargs):
    if args.quiet:
        return
    print(*fargs, file=sys.stderr, **fkwargs)


def info(*fargs, **fkwargs):
    if not args.verbose:
        return
    print(*fargs, file=sys.stderr, **fkwargs)


def quote(val):
    """Quote/escape a string in a safe way for Bourne-style shells."""
    if (
        val == ""
        or re.search(r"[][(){}<>;&|*?^!$`'\\\"\s]", val)
        or val[0] == "~"
        or re.search(r"[:=]~", val)
    ):
        return '"' + re.sub(r'([\\$"`])', r"\\\1", val) + '"'
    return val


def nodup(lst, key=None):
    dup = {}
    if key is None:
        return {e: None for e in lst}.keys()
    else:
        for e in lst:
            dup.setdefault(key(e), e)
        return dup.values()


def lsdirs(index):
    def lsdir(name, tag, meta, depth=0):
        subs = tags.get(tag)
        if subs is None:
            return [Dir(name=name, tag=tag, meta=meta, nosub=True)]
        named = name + ("/" if name else "")
        if depth > 100:
            err("directory too deep:", name)
            return [Dir(name + "...", tag, meta, True)]
        else:
            dirs = [Dir(name=name, tag=tag, meta=meta, nosub=False)]
            tsubs = defaultdict(list)
            dsubs = defaultdict(list)
            for s in subs:
                if (s.name, s.tag) not in tsubs:
                    dirs += lsdir(named + s.name, s.tag, s.meta, depth + 1)
                tsubs[(s.name, s.tag)].append(s.meta)
                dsubs[s.name].append(s.meta)
            for (d, t), mm in tsubs.items():
                if len(mm) > 1:
                    info(f"directory {named}{d} is on multiple servers:", " ".join(mm))
                dsubs.pop(d, None)
            for d, mm in dsubs.items():
                if len(mm) > 1:
                    err(f"directory {name}d{d} has multiple tags:", " ".join(mm))
            return dirs

    tags = defaultdict(list)
    with open(index, encoding="latin-1") as fin:
        n = 0
        lines = []
        joined = None
        for l in fin:
            n += 1
            line = l.rstrip("\n")
            if line == "" or " " in line or "/" in line or n <= 1:
                if joined is not None:
                    info(joined)
                    joined = None
                if line != "":
                    lines.append([line, n])
            else:
                last = lines[-1]
                if joined is None:
                    lastl, lastn = last
                    joined = f"{index}:{lastn}: lines joined: {lastl}"
                joined += f"\\n {line}"
                last[0] += "\n" + line
        if joined is not None:
            info(joined)

        for line, n in lines:
            flds = line.split(" ", 1)
            if not (len(flds) == 2 and "/" not in flds[0] and "/" in flds[-1]):
                err(f"{index}:{n}: bad format:", re.sub(r"\n", " ", line))
                continue
            tag, meta = flds
            meta = re.sub(r"\n", " ", meta)
            stag, sdir = meta.split("/")[-2:]
            tags[stag].append(Dir(name=sdir, tag=tag, meta=meta))

    dirs = []
    if args.user == "":
        dirs += lsdir("", "root", "")
    else:
        dd = tags.get("root")
        if dd is None:
            err(f"{index}: root directory not found")
        else:
            n = 0
            for d in dd:
                if d.name == args.user:
                    n += 1
                    dirs += lsdir(d.name, d.tag, d.meta)
            if n == 0:
                err(f"{index}: root directory not found:", args.user)

    # return list(set(dirs))   # nt so good - reorders the list
    return nodup(dirs, lambda d: (d.name, d.tag))  # unique tag/dir


def lsfiles2(index, dirs):
    dtag = defaultdict(list)
    dlen = {}
    for d in dirs:
        dlen[d.tag] = 0
        dtag[d.tag].append(d)
    for t, dd in dtag.items():
        if len(dd) != 1:
            err(f"multiple dirs for tag {t}:", " ".join([d.name for d in dd]))

    chunks = defaultdict(list)
    max_files = args.max_files
    if max_files is None:
        max_files = -1

    files = []
    with open(index, encoding="latin-1") as fin:
        n = 0
        for l in fin:
            n += 1
            if max_files >= 0 and n > max_files:
                break
            w = l.rstrip("\n").split(" ", 1)
            if not (len(w) == 2 and w[0].isdigit() and "/" in w[1]):
                err(f"{index}:{n}: bad format:", line)
                continue
            tag, meta = w
            ftag, fname = meta.split("/")[-2:]
            if ftag == "#fSiDs#":
                chunks[tag].append(fname)
            else:
                dd = dtag.get(ftag)
                if dd is not None:
                    dlen[ftag] += 1
                    files.append(
                        File(
                            dirs=dd,
                            name=fname,
                            tag=tag,
                            chunks=chunks.setdefault(tag, []),
                            empty=False,
                            meta=meta,
                        )
                    )

    if args.empty_directories:
        for t, n in dlen.items():
            if n != 0:
                continue
            dd = dtag.get(t)
            files.append(File(dirs=dd, empty=True, meta=dd[0].meta if dd else ""))
            for d in dd:
                info("empty dir:", d.name)

    return files


# put duplicate check in a separate function to reduce memory usage
def lsfiles(index, dirs):
    files = lsfiles2(index, dirs)
    dfiles = defaultdict(list)
    ufiles = []
    for f in files:
        for d in f.dirs:
            df = f"{d.name}/{f.name}"
            last = dfiles.get(df)
            if last is None:
                ufiles.append(f)
            dfiles[df].append(f)
    for df, ff in dfiles.items():
        if len(ff) > 1:
            err(
                f"file {df} has multiple tags:",
                " ".join([ff.tag for f in ff]) + ", chunks:",
                " ".join(nodup((c for f in ff for c in f.chunks))),
            )
    return ufiles


def lschunks(index, files):
    ctags = defaultdict(list)
    empty = []
    for f in files:
        fc = FileChunk(file=f, chunks=[[]] * len(f.chunks))
        if len(f.chunks) == 0:
            empty.append([fc])
            if f.name != "":
                info("empty file:", " ".join([d.name + "/" + f.name for d in f.dirs]))
            continue
        for c in f.chunks:
            # if len(f.chunks)>1, each element gets the same fc so we can update the appropriate bit for each chunk
            ctags[c].append(fc)

    for c, fcc in ctags.items():
        if len(fcc) > 1 or len(fcc[0].file.dirs) > 1:
            err(
                f"chunk {c} used in multiple files:",
                " ".join(
                    [d.name + "/" + fc.file.name for fc in fcc for d in fc.file.dirs]
                ),
            )

    chunks = []
    with open(index, encoding="latin-1") as fin:
        n = 0
        for l in fin:
            n += 1
            chunk = l.rstrip("\n")
            if " " in chunk or "/" not in chunk:
                err(f"{index}:{n}: bad format:", chunk)
                continue
            ctag = chunk.split("/")[-1]
            fcc = ctags.get(ctag)
            if fcc is not None:
                n = 0
                for fc in fcc:
                    n += sum([len(cc) for cc in fc.chunks])
                    fc.chunks[fc.file.chunks.index(ctag)].append(chunk)
                if n == 0:
                    # Only append the first time we see a chunk in this file. Other chunks will be added later.
                    chunks.append(fcc)

    for t, fcc in ctags.items():
        n = 0
        for fc in fcc:
            f = fc.file
            for d in f.dirs:
                if len(f.chunks) > 1:
                    err(
                        f"multiple chunks for file {d.name}/{f.name}:",
                        " ".join(
                            [
                                c
                                for cc in [
                                    fc.chunks[ic] if fc.chunks[ic] else [cc]
                                    for ic, cc in enumerate(f.chunks)
                                ]
                                for c in cc
                            ]
                        ),
                    )
                for ic, cc in enumerate(fc.chunks):
                    n += len(cc)
                    if len(cc) == 0:
                        err(f"file {d.name}/{f.name} chunk {f.chunks[ic]} not found")
                    elif len(cc) > 1:
                        info(
                            f"multiple storage instances for file {d.name}/{f.name} chunk {f.chunks[ic]}:",
                            " ".join(cc),
                        )
        if n == 0 and args.missing_chunks:
            chunks.append(fc)

    chunks += empty

    return chunks


def process():
    parse_args()
    idir = Path(args.dir)
    dirs = lsdirs(idir / "dir-metadata-index.txt")
    dest = Path(args.dest_dir)

    if args.output is not None:
        out = open(args.output, "w")
        if args.script:
            os.chmod(
                out.fileno(),
                os.stat(out.fileno()).st_mode
                | (stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH),
            )
    else:
        out = sys.stdout

    if args.list_directories:
        for d in nodup(dirs, lambda d: d.name):
            if args.tags:
                print(d.name + "\t" + d.tag, file=out)
            else:
                print(d.name, file=out)

    if args.list_files:
        files = lsfiles(idir / "file-metadata-index.txt", dirs)
        for f, t in nodup(
            ((f"{d.name}/{f.name}", f.tag) for f in files for d in f.dirs),
            lambda dft: dft[0],
        ):
            print(f + ("\t" + t if args.tags else ""), file=out)

    if args.list_chunks:
        chunks = lschunks(
            idir / "storage-chunk-index.txt",
            lsfiles(idir / "file-metadata-index.txt", dirs),
        )
        for df, cc, fcfc in nodup(
            (
                (
                    f"{d.name}/{fc.file.name}",
                    tuple(nodup((c for cc in fc.chunks for c in cc))),
                    fc.file.chunks,
                )
                for fcc in chunks
                for fc in fcc
                for d in fc.file.dirs
            ),
            lambda a: a[:2],
        ):
            print(
                str(dest / df)
                + ("\t" + " ".join(fcfc) if args.tags else "")
                + "\t"
                + " ".join((str(idir / c) for c in cc)),
                file=out,
            )

    if args.script:
        chunks = lschunks(
            idir / "storage-chunk-index.txt",
            lsfiles(idir / "file-metadata-index.txt", dirs),
        )

        udirs = {
            d.name: None
            for d in (d for fcc in chunks for fc in fcc for d in fc.file.dirs)
        }
        # remove redundent mkdir -p
        for d in list(udirs.keys()):
            while True:
                i = d.rfind("/")
                if i < 0:
                    break
                d = d[:i]
                if d in udirs:
                    udirs.pop(d, None)

        print("#!/bin/sh -x", file=out)
        for d in udirs.keys():
            print(f"mkdir -p", quote(str(dest / d)), file=out)

        for df, c, needsuf in nodup(
            (
                (f"{d.name}/{fc.file.name}", c, sum([len(cc) for cc in fc.chunks]) > 1)
                for fcc in chunks
                for fc in fcc
                for d in fc.file.dirs
                for cc in fc.chunks
                for c in cc
            ),
            lambda a: a[:2],
        ):
            print(
                args.command,
                quote(str(idir / c)),
                quote(str(dest / (df + ("." + c.split("/")[0] if needsuf else "")))),
                file=out,
            )

    if args.output is not None:
        out.close()


exit(process())
