#!/usr/bin/env python3

import sys, os, stat, pwd, grp, datetime, argparse, re, itertools, collections, binascii
from collections import defaultdict, namedtuple
from pathlib import Path
from array import array


class Uids(set):
    def __init__(self, s=set(), direct=False):
        self.update(s)
        self.direct = direct


Dir = namedtuple(
    "Dir", ["name", "tag", "metas", "nosub", "parent", "uids"]
)  # defaults=["", "", [], False, None, Uids]  # py3.7
File = namedtuple(
    "File", ["dir", "name", "tags", "chunks", "empty", "metas"]
)  # defaults=[Dir(), "", [], [], False, []] # py3.7
Chunk = namedtuple(
    "Chunk", ["tag", "meta", "stors", "xattr"]
)  # defaults=["", "", [], None]  # py3.7
FileStat = namedtuple("FileStat", ["name", "stat"])
StatResult = namedtuple(
    "StatResult",
    [
        "st_mode",
        "st_nlink",
        "st_uid",
        "st_gid",
        "st_size",
        "st_atime",
        "st_mtime",
        "st_ctime",
        "st_btime",
    ],
)
# don't use "st_ino", "st_dev"

server_decode = {
    0x0259: "mercury006",
    0x02BD: "mercury007",
    0x0321: "mercury008",
    0x0385: "mercury009",
    0x03E9: "mercury010",
    0x044D: "mercury011",
}

maxpath = 512
args = None
uids = {}
gids = {}


def parse_args():
    global args
    mydir = Path(sys.argv[0]).parent
    parser = argparse.ArgumentParser()
    parser.add_argument("-v", "--verbose", action="store_true")
    parser.add_argument("-q", "--quiet", action="store_true")
    parser.add_argument("-f", "--list-files", action="store_true")
    parser.add_argument("-d", "--list-directories", action="store_true")
    parser.add_argument("-c", "--list-chunks", action="store_true")
    parser.add_argument("-s", "--script", action="store_true")
    parser.add_argument("-e", "--empty-directories", action="store_true")
    parser.add_argument("-m", "--missing-chunks", action="store_true")
    parser.add_argument("-t", "--tags", action="store_true")
    parser.add_argument("-M", "--metadata", action="store_true")
    parser.add_argument("-O", "--chown", action="store_true")
    parser.add_argument("-x", "--xattr", action="store_true")
    parser.add_argument("-T", "--timestamps", action="store_true")
    parser.add_argument("-S", "--sizes", action="store_true")
    parser.add_argument("-H", "--hexdump", action="store_true")
    parser.add_argument("-j", "--no-merge", action="store_true")
    parser.add_argument(
        "-L",
        "--symlink",
        action="store_true",
        help="symlink instead of copying if possible. Also specify this if --command makes symlinks to prevent chmod being used.",
    )
    parser.add_argument("-X", "--xattr-dir")
    parser.add_argument("-n", "--max-files", type=int)
    parser.add_argument("-r", "--root_dir", default="")
    parser.add_argument("-u", "--user")
    parser.add_argument("-o", "--output")
    parser.add_argument("-C", "--command")
    parser.add_argument("--merge-command", default=mydir / "beegfs-merge-chunks")
    parser.add_argument("-D", "--dest-dir", default="")
    parser.add_argument("dir", nargs="?", default="")
    args = parser.parse_args()
    if not (
        args.list_directories or args.list_files or args.list_chunks or args.script
    ):
        args.script = True
    if args.command is None:
        args.command = "ln -sn" if args.symlink else "cp -n --preserve=timestamps"
    if (args.hexdump or args.xattr_dir) and not args.xattr:
        args.xattr = True
    if args.xattr and args.xattr_dir is None:
        args.xattr_dir = args.dir
    if args.xattr:
        args.xattr_dir = Path(args.xattr_dir)


def err(*fargs, **fkwargs):
    if args.quiet:
        return
    print(*fargs, file=sys.stderr, **fkwargs)


def info(*fargs, **fkwargs):
    if not args.verbose:
        return
    print(*fargs, file=sys.stderr, **fkwargs)


def quote(val):
    """Quote/escape a string in a safe way for Bourne-style shells."""
    if (
        val == ""
        or re.search(r"[][(){}<>;&|*?^!$`'\\\"\0- \x7F-\xFF]", val)
        or val[0] == "~"
        or re.search(r"[:=]~", val)
    ):
        return '"' + re.sub(r'([\\$"`])', r"\\\1", val) + '"'
    return val


def dirfile(dir, file):
    if dir:
        return f"{dir}/{file}"
    else:
        return file


def nodup(lst, key=None):
    if key is None:
        return dict.fromkeys(lst).keys()
    else:
        return {key(e): e for e in lst}.values()


def uextend(lst, ext, key=None):
    if key is None:
        for e in ext:
            if e not in lst:
                lst.append(e)
    else:
        k = [key(l) for l in lst]
        for e in ext:
            if key(e) not in k:
                lst.append(e)
                k.append(key(e))


def filestat(idir, s):
    f = idir / s
    try:
        st = f.stat()
    except IOError:
        st = None
    return FileStat(s if args.metadata else f, st)


def hexdump(data, size=2, sep=" "):
    """Generator that produces lines of a hex dump to print
    binary data line by line to the hex dump text format:
    00000000: 00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  ................
    based on hexdump package from https://pypi.org/project/hexdump/"""
    for addr, d in enumerate(hexchunks(data, 16)):
        # 00000000:
        line = "%08X: " % (addr * 16)
        # 00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00
        dumpstr = sep.join(hexchunks(binascii.hexlify(d).decode("ascii").upper(), size))
        line += dumpstr[: 8 * 3]
        if len(d) > 8:  # insert separator if needed
            line += " " + dumpstr[8 * 3 :]
        # calculate indentation, which may be different for the last line
        pad = 2
        if len(d) < 16:
            pad += 3 * (16 - len(d))
        if len(d) <= 8:
            pad += 1
        line += " " * pad

        for byte in d:
            # printable ASCII range 0x20 to 0x7E
            if 0x20 <= byte <= 0x7E:
                line += chr(byte)
            else:
                line += "."
        yield line


def hexchunks(seq, size):
    """Generator that cuts sequence (bytes, memoryview, etc.)
    into chunks of given size. If `seq` length is not multiply
    of `size`, the lengh of the last chunk returned will be
    less than requested.
    >>> list( chunks([1,2,3,4,5,6,7], 3) )
    [[1, 2, 3], [4, 5, 6], [7]]"""
    d, m = divmod(len(seq), size)
    for i in range(d):
        yield seq[i * size : (i + 1) * size]
    if m:
        yield seq[d * size :]


def getxattr(meta):
    try:
        return os.getxattr(args.xattr_dir / meta, "user.fhgfs")
    except IOError as e:
        err(e)
        return b""


def xattr_offset(lxattr):
    # xattrlens = [140, 142, 144, 160, 162, 172, 176, 182, 192, 202]
    if lxattr >= 0xCA:  # 202
        return 0x28, 0x3C
    elif lxattr >= 0xC0:  # 192
        return 0x20, 0x34
    elif lxattr >= 0xB6:  # 182
        return 0x28, 0x28
    elif lxattr >= 0xB0:  # 176
        return 0x20, 0x24
    elif lxattr >= 0xAC:  # 172
        return 0x20, 0x20
    elif lxattr >= 0xA0:  # 160
        return 0x00, 0x14
    elif lxattr >= 0x90:  # 144
        return 0x00, 0x04
    else:
        return 0x00, 0x00


def getservers(xattr, f, minservers=2):
    i, j = xattr_offset(len(xattr))
    if len(xattr) < j + 0x7E + 2 * minservers:
        err(f"file {filename} xattr length {len(xattr)} is too short")
        return {}
    # tag = str(xattr[j + 0x54 : j + 0x64]).rtrim("\0")
    server_codes = [
        int.from_bytes(xattr[a : a + 2], "little")
        for a in range(j + 0x7E, len(xattr) - 1, 2)
    ]
    while server_codes and server_codes[-1] == 0:
        server_codes.pop()
    servers = {server_decode.get(s, ""): i for i, s in enumerate(server_codes)}
    if any([not s for s in servers.keys()]):
        err(
            f"file {dirfile(f.dir.name, f.name)} bad server codes:",
            " ".join(f"{x:02X}" for x in server_codes if x is not None),
        )
    return servers


def getstat(xattr, filename):
    def getint(l, h, i=0):
        return int.from_bytes(xattr[i + l : i + h], "little")

    i, j = xattr_offset(len(xattr))
    if len(xattr) < i + 0x50:
        err(f"file {filename} xattr length {len(xattr)} is too short")
        return None
    st = StatResult(
        st_mode=getint(0x14, 0x18),
        st_mtime=getint(0x18, 0x20, i),  # not sure if we swapped m/c/a/btime
        st_ctime=getint(0x20, 0x28, i),
        st_atime=getint(0x28, 0x30, i),
        st_btime=getint(0x30, 0x38, i),
        st_size=getint(0x38, 0x40, i),
        st_nlink=getint(0x40, 0x48, i),  # just a guess, since this is always 1
        st_uid=getint(0x48, 0x4C, i),
        st_gid=getint(0x4C, 0x50, i),
        # st_unknown=getint(0x50, 0x54, i),
    )
    if st.st_mode != (stat.S_IFMT(st.st_mode) | stat.S_IMODE(st.st_mode)) or not (
        stat.S_ISREG(st.st_mode) or stat.S_ISLNK(st.st_mode) or stat.S_ISDIR(st.st_mode)
    ):
        err(f"file {filename} bad mode: 0{st.st_mode:o}")
    if getpwuid(st.st_uid) is None or getgrgid(st.st_gid) is None:
        err(f"file {filename} bad UID:GID {st.st_uid}:{st.st_gid}")
    return st


def getpwuid(uid):
    pw = uids.get(uid)
    if pw is not None:
        return pw
    try:
        pw = pwd.getpwuid(uid)
    except KeyError:
        return None
    uids[uid] = pw
    return pw


def getgrgid(gid):
    gr = gids.get(gid)
    if gr is not None:
        return gr
    try:
        gr = grp.getgrgid(gid)
    except KeyError:
        return None
    gids[gid] = gr
    return gr


def filemode(st):
    return stat.filemode(st.st_mode) if st.st_mode is not None else ""


def owner(st):
    uid, gid = st.st_uid, st.st_gid
    if uid is None or gid is None:
        return ""
    pw = getpwuid(uid)
    if pw is not None:
        uid = pw.pw_name
    gr = getgrgid(gid)
    if gr is not None:
        gid = gr.gr_name
    return f"{uid}:{gid}"


def times(st):
    def time(t):
        return datetime.datetime.fromtimestamp(t).isoformat() if t else ""

    return (
        time(st.st_atime)
        + " "
        + time(st.st_mtime)
        + " "
        + time(st.st_ctime)
        + " "
        + time(st.st_btime)
    )


def list_stor(f, info=False, abs=True):
    fname = dirfile(f.dir.name, f.name)
    files = [s for s in nodup(s for c in f.chunks for s in c.stors)]
    unsorted = len(files) > 1
    if args.xattr and unsorted and f.chunks[0].xattr:
        servers = getservers(f.chunks[0].xattr, f)
        stfiles = [FileStat(s, servers.get(s.split("/")[0], -1)) for s in files]
        bad = [fs.name for fs in stfiles if fs.stat == -1]
        if bad:
            err(
                f"file {fname} no xattr for servers",
                " ".join(bad),
            )
        stfiles.sort(key=lambda fs: fs.stat)
        unsorted = False
        files = [s.name for s in stfiles]
    if args.sizes and (info or unsorted or args.xattr):
        idir = Path(args.dir)
        stfiles = [filestat(idir, s) for s in files]
        if unsorted:
            stfiles.sort(key=lambda f: (-f.stat.st_size, f.stat.st_mtime_ns))
            files = [s.name for s in stfiles]
        sz = sum(fs.stat.st_size for fs in stfiles)
        if args.xattr:
            if f.chunks:
                st = getstat(f.chunks[0].xattr, fname)
                szstor = st.st_size if st else None
            else:
                szstor = 0
            if szstor is not None and szstor != sz:
                err(f"file {fname} size should be {szstor}, but is {sz} on disk")
        if info:
            return [
                f"{fs.name} ({fs.stat.st_size},0x{fs.stat.st_size:X})" for fs in stfiles
            ] + ([f"(={sz},0x{sz:X})"] if len(stfiles) > 1 else [])
    if abs:
        return [str(Path(args.dir) / s) for s in files]
    else:
        return files


def list_metadata(f):
    def statinfo(xattr):
        st = getstat(xattr, dirfile(f.dir.name, f.name))
        if not st:
            return ""
        return (
            filemode(st)
            + " "
            + owner(st)
            + " "
            + str(st.st_size)
            + f" ({str(len(xattr))})"
            + (" " + times(st) if args.timestamps else "")
        )

    return (
        (
            "\t"
            + " ".join(f.dir.metas)
            + "\t"
            + " ".join(nodup(c.meta for c in f.chunks))
            if args.metadata
            else ""
        )
        + (
            "\t" + " ".join(statinfo(c.xattr) for c in f.chunks if c.xattr)
            if args.xattr
            else ""
        )
        + (
            "".join(["\n" + l for c in f.chunks for l in hexdump(c.xattr)])
            if args.hexdump
            else ""
        )
    )


def lsdirs(index):
    def lsdir(name, tag, metas, parent=None, select="", top=None, depth=0):
        subs = tags.get(tag)
        if subs is None:
            if (name + "/").startswith(select):
                return [
                    Dir(
                        name=name,
                        tag=tag,
                        metas=metas,
                        parent=parent,
                        nosub=True,
                        uids=Uids(),
                    )
                ]
            else:
                return []
        named = name + ("/" if name else "")
        if depth > 100:
            if (name + "/").startswith(select):
                err("directory too deep:", name)
                return [
                    Dir(
                        name=name + "...",
                        tag=tag,
                        metas=metas,
                        parent=parent,
                        nosub=True,
                        uids=Uids(),
                    )
                ]
            else:
                return []
        else:
            this = Dir(
                name=name, tag=tag, metas=metas, parent=parent, nosub=False, uids=Uids()
            )
            if (name + "/").startswith(select):
                dirs = [this]
            else:
                dirs = []
            tsubs = defaultdict(list)
            dsubs = defaultdict(list)
            for s in subs:
                if top is not None and s.name == top:
                    metas.extend(s.metas)
                    continue
                tsub = tsubs.setdefault((s.name, s.tag), [])
                tsub.extend(s.metas)
                if len(tsub) == 1:
                    dirs += lsdir(
                        name=named + s.name,
                        tag=s.tag,
                        metas=tsub,
                        parent=this,
                        select=select,
                        depth=depth + 1,
                    )
                dsubs[s.name].append(s.metas)
            for (d, t), mm in tsubs.items():
                if len(mm) > 1:
                    info(f"directory {named}{d} has multiple metadata:", " ".join(mm))
                dsubs.pop(d, None)
            for d, mm in dsubs.items():
                if len(mm) > 1:
                    info(f"directory {named}{d} has multiple tags:", " ".join(mm))
            return dirs

    tags = defaultdict(list)
    with open(index, encoding="latin-1") as fin:
        n = 0
        lines = []
        joined = None
        for l in fin:
            n += 1
            line = l.rstrip("\n")
            if line == "" or " " in line or "/" in line or n <= 1:
                if joined is not None:
                    info(joined)
                    joined = None
                if line != "":
                    lines.append([line, n])
            else:
                last = lines[-1]
                if joined is None:
                    lastl, lastn = last
                    joined = f"{index}:{lastn}: lines joined: {lastl}"
                joined += f"\\n {line}"
                last[0] += "\n" + line
        if joined is not None:
            info(joined)

        for line, n in lines:
            flds = line.split(" ", 1)
            if not (len(flds) == 2 and "/" not in flds[0] and "/" in flds[-1]):
                info(
                    f"{index}:{n}: bad format [known issue]:", re.sub(r"\n", " ", line)
                )
                continue
            tag, meta = flds
            meta = re.sub(r"\n", " ", meta)
            stag, sdir = meta.split("/")[-2:]
            tags[stag].append(
                Dir(
                    name=sdir,
                    tag=tag,
                    metas=[meta],
                    parent=None,
                    nosub=False,
                    uids=Uids(),
                )
            )

    dirs = lsdir(
        name="",
        tag="root",
        metas=[],
        top="root",
        select=args.root_dir + "/" if args.root_dir else "",
    )
    return nodup(dirs, lambda d: (d.name, d.tag))  # unique tag/dir


def lsfiles2(index, dirs):
    dtag = defaultdict(list)
    dlen = {}
    for d in dirs:
        dlen[d.tag] = 0
        dtag[d.tag].append(d)
    for t, dd in dtag.items():
        if len(dd) != 1:
            err(f"multiple dirs for tag {t}:", " ".join([d.name for d in dd]))

    chunks = defaultdict(list)

    files = []
    with open(index, encoding="latin-1") as fin:
        n = 0
        for l in fin:
            n += 1
            if args.max_files is not None and n > args.max_files:
                break
            w = l.rstrip("\n").split(" ", 1)
            if not (len(w) == 2 and w[0].isdigit() and "/" in w[1]):
                err(f"{index}:{n}: bad format:", line)
                continue
            tag, meta = w
            ftag, fname = meta.split("/")[-2:]
            if ftag == "#fSiDs#":
                chunks[tag].append(
                    Chunk(tag=fname, meta=meta, stors=[], xattr=array("B"))
                )
            else:
                dd = dtag.get(ftag)
                if dd is not None:
                    dlen[ftag] += len(dd)
                    i = meta.rfind("/")
                    xmeta = meta[:i] if i >= 0 else meta
                    for d in dd:
                        files.append(
                            File(
                                dir=d,
                                name=fname,
                                tags=[tag],
                                chunks=chunks.setdefault(tag, []),
                                empty=False,
                                metas=[xmeta],
                            )
                        )

    if args.empty_directories:
        for t, n in dlen.items():
            if n > 0:
                dd = dtag.get(t)
                for d in dd:
                    if d.nosub:
                        files.append(
                            File(
                                dir=d,
                                name="",
                                tags=[d.tag],
                                chunks=[],
                                empty=True,
                                metas=d.metas,
                            )
                        )
                        info("empty dir:", d.name)

    return files


# put duplicate check in a separate function to reduce memory usage
def lsfiles(index, dirs):
    files = lsfiles2(index, dirs)
    dfiles = {}
    ufiles = []
    for f in files:
        df = dirfile(f.dir.name, f.name)
        last = dfiles.get(df)
        if last is None:
            ufiles.append(f)
            dfiles[df] = f
        else:
            uextend(last.tags, f.tags)
            uextend(last.metas, f.metas)
            uextend(last.chunks, f.chunks, lambda c: c.tag)
    for f in ufiles:
        if args.xattr:
            # read xattr only for files in a selected directory
            for c in f.chunks:
                if not c.xattr:
                    c.xattr.frombytes(getxattr(c.meta))

        if len(f.tags) > 1:
            info(
                "file",
                dirfile(f.dir.name, f.name),
                "has multiple tags:",
                " ".join(f.tags) + ", chunks:",
                " ".join(nodup((c.tag for c in f.chunks))),
            )
    return ufiles


def lschunks(index, files):
    re_uid = None
    if args.user is not None:
        try:
            pw = pwd.getpwnam(args.user)
        except KeyError:
            err("user", args.user, "not found")
        else:
            re_uid = re.compile(r"^[^/]+/storage/chunks/u" + f"{pw.pw_uid:X}/")

    ctags = defaultdict(list)
    empty = []
    for f in files:
        if len(f.chunks) == 0:
            empty.append(f)
            if f.name != "":
                info("empty file:", dirfile(f.dir.name, f.name))
        for c in f.chunks:
            # if len(f.chunks)>1, each element gets the same f so we can update the appropriate bit for each chunk
            ctags[c.tag].append(f)

    for t, ff in ctags.items():
        if len(ff) > 1:
            err(
                f"chunk {t} used in multiple files:",
                " ".join(f.dir.name + "/" + f.name for f in ff),
            )
            # uff = nodup(f.dir.name + "/" + f.name for f in ff)
            # if len(uff) > 1:
            # err(f"chunk {t} used in multiple files:", " ".join(uff))

    cfiles = []
    with open(index, encoding="latin-1") as fin:
        n = 0
        for l in fin:
            n += 1
            chunk = l.rstrip("\n")
            if " " in chunk or "/" not in chunk:
                err(f"{index}:{n}: bad format:", chunk)
                continue
            ctag = chunk.split("/")[-1]
            if re_uid is not None and not re.match(re_uid, chunk):
                continue
            ff = ctags.get(ctag)
            if ff is not None:
                for f in ff:
                    n = 0
                    for c in f.chunks:
                        n += len(c.stors)
                        if c.tag == ctag:  # should always match exactly once
                            c.stors.append(chunk)
                    if n == 0:
                        # Only append the first time we see a chunk in this file. Other chunks will be added later.
                        cfiles.append(f)

    for t, ff in ctags.items():
        for f in ff:
            n = 0
            if len(f.chunks) > 1:
                err(
                    "multiple chunks for file",
                    dirfile(f.dir.name, f.name) + ":",
                    " ".join([c.tag for c in f.chunks]),
                )
            for c in f.chunks:
                n += len(c.stors)
                if len(c.stors) == 0:
                    if args.user is None:
                        err(
                            "file",
                            dirfile(f.dir.name, f.name),
                            f"chunk {c.tag} not found",
                        )
                elif len(c.stors) > 1:
                    info(
                        "multiple storage instances for file",
                        dirfile(f.dir.name, f.name),
                        f"chunk {c.tag}:",
                        " ".join(c.stors),
                    )
            if n == 0 and args.missing_chunks:
                cfiles.append(f)

    cfiles += empty

    return cfiles


def list_dirs(dirs, out):
    for d in nodup(dirs, lambda d: d.name):
        print(
            d.name
            + ("\t" + d.tag if args.tags else "")
            + ("\t" + " ".join(d.metas) if args.metadata else ""),
            file=out,
        )


def list_files(files, out):
    for f in nodup(files, lambda f: (f.dir.name, f.name)):
        print(
            dirfile(f.dir.name, f.name)
            + ("\t" + " ".join(f.tags) if args.tags else "")
            + list_metadata(f),
            file=out,
        )


def list_chunks(cfiles, out):
    idir = Path(args.dir)
    dest = Path(args.dest_dir)
    for f in nodup(
        cfiles,
        lambda f: (
            f.dir.name,
            f.name,
            tuple(nodup((s for c in f.chunks for s in c.stors))),
        ),
    ):
        print(
            str(dest / dirfile(f.dir.name, f.name))
            + "\t"
            + " ".join(list_stor(f, info=True, abs=not args.metadata))
            + ("\t" + " ".join(nodup((c.tag for c in f.chunks))) if args.tags else "")
            + list_metadata(f),
            file=out,
        )


def list_script(cfiles, out):
    idir = Path(args.dir)
    dest = Path(args.dest_dir)

    udirs = {f.dir.name: f.dir for f in cfiles}
    # remove redundent mkdir -p
    for d in list(udirs.values()):
        while d.parent:
            d = d.parent
            if d.name in udirs:
                udirs.pop(d.name, None)

    print("#!/bin/bash", file=out)
    print("set -x", file=out)
    for d in udirs.keys():
        print("mkdir -p", quote(str(dest / d)), file=out)
    del udirs

    files = []
    for f in cfiles:
        fname = dirfile(f.dir.name, f.name)
        if args.no_merge:
            usesuf = len(f.chunks) > 1 or sum([len(c.stors) for c in f.chunks]) > 1
            for c in f.chunks:
                if c.stors:
                    for i, s in enumerate(c.stors):
                        files.append(
                            (
                                fname + ("." + s.split("/")[0] if usesuf else ""),
                                i,
                                [s],
                                f.dir,
                                c.xattr,
                            )
                        )
                else:
                    files.append((fname, 1, [c.meta], f.dir, c.xattr))
        else:
            s = list_stor(f)
            if s:
                files.append(
                    (fname, 1, s, f.dir, f.chunks[0].xattr if f.chunks else b"")
                )
            elif f.chunks:
                c = f.chunks[0]
                files.append((fname, 1, [c.meta], f.dir, c.xattr))

    for df, ifile, s, d, xattr in nodup(files, lambda l: l[:2]):
        fname = quote(str(dest / df))
        islink = False
        if args.xattr:
            st = getstat(xattr, df)
            if st and len(s) == 1:
                islink = stat.S_ISLNK(st.st_mode)
                if islink and not (st.st_size and st.st_size < maxpath):
                    err("symlink {fname} target length is", st.st_size)
                    islink = False
        if islink:
            print(f'ln -sn "$(< {quote(str(idir / s[0]))})"', fname, file=out)
        elif len(s) == 1:
            print(args.command, quote(str(idir / s[0])), fname, file=out)
        else:
            print(
                args.merge_command,
                "-o",
                fname,
                " ".join([quote(ss) for ss in s]),
                file=out,
            )
        if args.xattr and st:
            if not islink:
                print(
                    f"[ -h {fname} ] || \\\nchmod 0{stat.S_IMODE(st.st_mode):o}",
                    fname,
                    file=out,
                )
            if args.chown:
                print("chown -h", f"{st.st_uid}:{st.st_gid}", fname, file=out)
        if args.chown and not args.xattr:
            um = re.match(r"^[^/]+/storage/chunks/u([\da-fA-F]+)/", s[0])
            if um:
                uid = int(um.groups()[0], 16)
                pw = getpwuid(uid)
                ugid = f"{uid}:{pw.pw_gid}" if pw is not None else f"{uid}"
                d.uids.add(uid)
                d.uids.direct = True
                print("chown -h", ugid, fname, file=out)
    del files

    # find all needed dirs and their parents
    udirs = {}
    for f in cfiles:
        d = f.dir
        udirs.setdefault(d.name, d)
        while d.parent:
            if d.uids and not d.parent.uids.direct:
                d.parent.uids.update(d.uids)
            d = d.parent
            udirs.setdefault(d.name, d)

    for d in udirs.values():
        if args.chown and not args.xattr:
            if not d.uids:
                dp = d
                while dp.parent:
                    dp = dp.parent
                    if dp.uids:
                        d.uids.update(dp.uids)
                        break
            if d.uids:
                if len(d.uids) > 1:
                    err(
                        "dir",
                        d.name,
                        "multiple uids:",
                        " ".join([uids[u] for u in d.uids]),
                    )
                print(
                    "chown -h",
                    uids[next(iter(d.uids))],
                    quote(str(dest / d.name)),
                    file=out,
                )
            else:
                err("dir", d.name, "has no UID")

        if len(d.metas) == 1:
            print(
                "touch -r",
                quote(str(idir / d.metas[0])),
                quote(str(dest / d.name)),
                file=out,
            )
        elif len(d.metas) > 1:
            print(
                "touch -r $(ls -1dt",
                " ".join([quote(str(idir / m)) for m in d.metas]),
                "| head -1)",
                quote(str(dest / d.name)),
                file=out,
            )


def list_all(out):
    idir = Path(args.dir)

    dirs = lsdirs(idir / "dir-metadata-index.txt")

    if args.list_directories:
        list_dirs(dirs, out)

    if args.list_files or args.list_chunks or args.script:
        files = lsfiles(idir / "file-metadata-index.txt", dirs)
        del dirs

    if args.list_files:
        list_files(files, out)

    if args.list_chunks or args.script:
        cfiles = lschunks(idir / "storage-chunk-index.txt", files)
        del files

    if args.list_chunks:
        list_chunks(cfiles, out)
    if args.script:
        list_script(cfiles, out)


def process():
    global maxpath
    parse_args()
    maxpath = os.pathconf(str(Path(args.dest_dir)), "PC_PATH_MAX")

    if args.output is not None:
        out = open(args.output, "w")
        if args.script:
            os.chmod(
                out.fileno(),
                os.stat(out.fileno()).st_mode
                | (stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH),
            )
    else:
        out = sys.stdout

    list_all(out)

    if args.output is not None:
        out.close()

    return 0


exit(process())
