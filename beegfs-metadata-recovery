#!/usr/bin/env python3

import sys, os, stat, pwd, grp, datetime, argparse, re, binascii
from collections import defaultdict, namedtuple
from pathlib import Path


def parse_args():
    global args
    mydir = Path(sys.argv[0]).parent
    prog = Path(sys.argv[0]).name
    parser = argparse.ArgumentParser(
        description=f"""
Recovers files from a broken beegfs filesystem's metadata.

## Recovering files

```
# Start with:
#     /opt/ppd/scratch/data2_recovery/mercury???/meta.tgz
#     /opt/ppd/scratch/data2_recovery/mercury???/storage/chunks/...

# Extract the metadata files to a local disk, so they keep their xattr:
cd /scratch/adye/data2_recovery
mkdir $(cd /opt/ppd/scratch/data2_recovery; ls -1d mercury???)
for d in mercury???; do cp -pi /opt/ppd/scratch/data2_recovery/$d/meta.tgz $d/; done
for d in mercury???; do (set -x; cd $d; tar --xattrs -zxf meta.tgz); done

# Creates directories:
#     mercury00?/meta/dentries
#     mercury00?/meta/buddymir/dentries
#     mercury00?/meta/inodes
#     mercury00?/meta/buddymir/inodes

# Create stor.txt with the list of storage chunks:
cd /opt/ppd/scratch/data2_recovery
find mercury???/storage/chunks -type f > /scratch/adye/data2_recovery/stor.txt

# Create meta.txt with all the metadata from the meta directories:
cd /scratch/adye/data2_recovery
{prog} -w -o /scratch/adye/data2_recovery/meta.txt /scratch/adye/data2_recovery
# With -x checks xattr metadata matches between different server's instances of the same data

# Create copy.sh:
cd /mercury/data2/restore
{prog} -o copy.sh -D restore -G /opt/ppd/scratch/data2_recovery /scratch/adye/data2_recovery
# With -O includes chown commands, which requires root.
# With -S checks storage file sizes (slower).
# With -x checks xattr metadata matches between dentries and file inodes (more RAM?)

# Run copy.sh:
./copy.sh
```

## Notes

* This script requires Python 3.6 or greater, as is default on CentOS7.

* The final script (copy.sh in this example) uses the `beegfs-merge-chunks` script,
executed from the same directory as this `beegfs-metadata-recovery`.

* If recovering a different filesystem from what I used, check the server_decode
and (just to supress some error messages) topdirs below.
""",
        formatter_class=argparse.RawTextHelpFormatter,
    )
    parser.add_argument("-v", "--verbose", action="store_true")
    parser.add_argument("-q", "--quiet", action="store_true")
    parser.add_argument("-0", "--list-meta", action="store_true")
    parser.add_argument("-f", "--list-files", action="store_true")
    parser.add_argument("-d", "--list-directories", action="store_true")
    parser.add_argument("-c", "--list-chunks", action="store_true")
    parser.add_argument("-s", "--script", action="store_true")
    parser.add_argument("-E", "--no-empty-directories", action="store_true")
    parser.add_argument("-M", "--no-missing-chunks", action="store_true")
    parser.add_argument("-t", "--tags", action="store_true")
    parser.add_argument("-m", "--metadata", action="store_true")
    parser.add_argument("-O", "--chown", action="store_true")
    parser.add_argument("-X", "--no-xattr", action="store_true")
    parser.add_argument("-T", "--timestamps", action="store_true")
    parser.add_argument(
        "-S",
        "--sizes",
        action="store_true",
        help="With --xattr, check size against xattr. Otherwise can be used to sort chunks, albeit not perfectly",
    )
    parser.add_argument("-H", "--hexdump", action="store_true")
    parser.add_argument("-j", "--no-merge", action="store_true")
    parser.add_argument(
        "-L",
        "--symlink",
        action="store_true",
        help="symlink instead of copying if possible. Also specify this if --command makes symlinks to prevent chmod being used.",
    )
    parser.add_argument("-w", "--walk", action="store_true")
    parser.add_argument("-x", "--check-xattr", action="store_true")
    parser.add_argument("-n", "--max-files", type=int)
    parser.add_argument("-N", "--max-depth", type=int, default=100)
    parser.add_argument("-r", "--root_dir", default="")
    parser.add_argument("-u", "--user")
    parser.add_argument("-o", "--output")
    parser.add_argument("-C", "--command")
    parser.add_argument("--merge-command", default=mydir / "beegfs-merge-chunks")
    parser.add_argument("-D", "--dest-dir", default="")
    parser.add_argument("-G", "--storage-dir")
    parser.add_argument("dir", nargs="?", default="")
    args = parser.parse_args()
    if not (
        args.walk
        or args.list_meta
        or args.list_directories
        or args.list_files
        or args.list_chunks
        or args.script
    ):
        args.script = True
    if args.command is None:
        args.command = "ln -sn" if args.symlink else "cp -n --preserve=timestamps"
    if (args.walk or args.hexdump) and args.no_xattr:
        args.no_xattr = False
    if args.storage_dir is None:
        args.storage_dir = args.dir


class Uids(set):
    def __init__(self, s=set(), direct=False):
        self.update(s)
        self.direct = direct


FileMeta = namedtuple("FileMeta", ["tag", "dir", "meta", "xattr"])
DirMeta = namedtuple("DirMeta", ["name", "tag", "inode", "meta", "xattr"])
DentMeta = namedtuple(
    "DentMeta", ["name", "tag", "dir", "file", "meta", "links", "xattr"]
)
InodeMeta = namedtuple("InodeMeta", ["tag", "meta", "xattr"])
Dir = namedtuple(
    "Dir", ["name", "tag", "metas", "nosub", "parent", "uids", "inode", "xattr"]
)  # defaults=["", "", [], False, None, Uids, [], b""]  # py3.7
File = namedtuple(
    "File",
    ["dir", "name", "tag", "inode", "stors", "emptydir", "meta", "links", "xattr"],
)  # defaults=[Dir(), "", [], [], False, [], [], b""] # py3.7
FileStat = namedtuple("FileStat", ["name", "stat"])
StatResult = namedtuple(
    "StatResult",
    [
        "st_mode",
        "st_nlink",
        "st_uid",
        "st_gid",
        "st_size",
        "st_atime",
        "st_mtime",
        "st_ctime",
        "st_btime",
    ],  # don't use "st_ino", "st_dev"
)


server_decode = {
    0x0259: "mercury006",
    0x02BD: "mercury007",
    0x0321: "mercury008",
    0x0385: "mercury009",
    0x03E9: "mercury010",
    0x044D: "mercury011",
}

maxpath = 512
args = None
uids = {}
gids = {}
topdirs = {"root", "disposal", "mdisposal"}


def err(*fargs, **fkwargs):
    if args.quiet:
        return
    print(*fargs, file=sys.stderr, **fkwargs)


def info(*fargs, **fkwargs):
    if not args.verbose:
        return
    print(*fargs, file=sys.stderr, **fkwargs)


def quote(val):
    """Quote/escape a string in a safe way for Bourne-style shells."""
    if (
        val == ""
        or re.search(r"[][(){}<>;&|*?^!$`'\\\"\0- \x7F-\xFF]", val)
        or val[0] == "~"
        or re.search(r"[:=]~", val)
    ):
        return '"' + re.sub(r'([\\$"`])', r"\\\1", val) + '"'
    return val


def dirfile(dir, file):
    if dir:
        return f"{dir}/{file}"
    else:
        return file


def nodup(lst, key=None, destroy=False):
    if key is None:
        r = dict.fromkeys(lst).keys()
    else:
        r = {key(e): e for e in lst}.values()
    if destroy:
        del lst
    return r


def uextend(lst, ext, key=None):
    if key is None:
        for e in ext:
            if e not in lst:
                lst.append(e)
    else:
        k = [key(l) for l in lst]
        for e in ext:
            if key(e) not in k:
                lst.append(e)
                k.append(key(e))


def filestat(idir, s):
    f = idir / s
    try:
        st = f.stat()
    except IOError:
        st = None
    return FileStat(s, st)


def hexdump(data, firstnl=True):
    if args.hexdump:
        return ("\n" if firstnl and len(data) else "") + "\n".join(hexdump_gen(data))
    else:
        return ""


def hexdump_gen(data, size=2, sep=" "):
    """Generator that produces lines of a hex dump to print
    binary data line by line to the hex dump text format:
    00000000: 00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  ................
    based on hexdump package from https://pypi.org/project/hexdump/"""
    for addr, d in enumerate(hexchunks(data, 16)):
        # 00000000:
        line = "%08X: " % (addr * 16)
        # 00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00
        dumpstr = sep.join(hexchunks(binascii.hexlify(d).decode("ascii").upper(), size))
        line += dumpstr[: 8 * 3]
        if len(d) > 8:  # insert separator if needed
            line += " " + dumpstr[8 * 3 :]
        # calculate indentation, which may be different for the last line
        pad = 2
        if len(d) < 16:
            pad += 3 * (16 - len(d))
        if len(d) <= 8:
            pad += 1
        line += " " * pad

        for byte in d:
            # printable ASCII range 0x20 to 0x7E
            if 0x20 <= byte <= 0x7E:
                line += chr(byte)
            else:
                line += "."
        yield line


def hexchunks(seq, size):
    """Generator that cuts sequence (bytes, memoryview, etc.)
    into chunks of given size. If `seq` length is not multiply
    of `size`, the lengh of the last chunk returned will be
    less than requested.
    >>> list( chunks([1,2,3,4,5,6,7], 3) )
    [[1, 2, 3], [4, 5, 6], [7]]"""
    d, m = divmod(len(seq), size)
    for i in range(d):
        yield seq[i * size : (i + 1) * size]
    if m:
        yield seq[d * size :]


def getxattr(fname, aname="user.fhgfs"):
    try:
        return os.getxattr(fname, aname)
    except IOError as e:
        err(e)
        return b""


def xattr_offset(lxattr):
    # xattrlens = [32, 140, 142, 144, 160, 162, 172, 176, 182, 192, 202]
    #          itag, imode,itime,isize,iuid, iserv
    if lxattr >= 0xCA:  # 202
        return 0x90, 0x00, 0x28, 0x28, 0x28, 0x3C
    elif lxattr >= 0xC0:  # 192
        return 0x88, 0x00, 0x20, 0x20, 0x20, 0x34
    elif lxattr >= 0xB6:  # 182
        return 0x7C, 0x00, 0x28, 0x28, 0x28, 0x28
    elif lxattr >= 0xB0:  # 176
        return 0x78, 0x00, 0x20, 0x20, 0x20, 0x24
    elif lxattr >= 0xAC:  # 172
        return 0x74, 0x00, 0x20, 0x20, 0x20, 0x20
    elif lxattr >= 0xA0:  # 160
        return 0x68, 0x00, 0x00, 0x00, 0x00, 0x14
    elif lxattr >= 0x90:  # 144
        return 0x58, 0x00, 0x00, 0x00, 0x00, 0x04
    elif lxattr >= 0x8C:  # 140
        return 0x54, 0x00, 0x00, 0x00, 0x00, 0x00
    elif lxattr >= 0x20:  # 32
        return 0x0C, None, None, None, None, None
    else:
        return None, None, None, None, None, None


def xattr_offset_inode(lxattr):
    # xattrlens = [114, 126, 134]
    #          itag, imode, itime,isize,  iuid, iserv
    if lxattr >= 0x86:  # 134
        return 0x40, -0x08, -0x08, None, -0x18, None
    elif lxattr >= 0x7E:  # 126
        return 0x40, -0x08, -0x08, None, -0x18, None
    elif lxattr >= 0x72:  # 114
        return 0x40, -0x08, -0x08, None, -0x18, None
    else:
        return None, None, None, None, None, None


def gettag(xattr, filename, offset_fun=xattr_offset):
    if not xattr:
        return ""
    itag, *_ = offset_fun(len(xattr))
    if itag is None:
        return ""
    tag = b2str(xattr[itag + 0x00 : itag + 0x10]).rstrip("\0")
    if not re.match(r"[\dA-F]+-[\dA-F]+-[\dA-F]+$", tag) and tag not in topdirs:
        err(f"file {filename} bad tag:", repr(tag))
    return tag


def getservers(xattr, filename, minservers=2):
    if not xattr:
        return {}
    _, _, _, _, _, iserv = xattr_offset(len(xattr))
    if iserv is None or len(xattr) < iserv + 0x7E + 2 * minservers:
        err(f"file {filename} xattr length {len(xattr)} is too short")
        return {}
    # tag = str(xattr[iserv + 0x54 : iserv + 0x64]).rtrim("\0")
    server_codes = [
        int.from_bytes(xattr[a : a + 2], "little")
        for a in range(iserv + 0x7E, len(xattr) - 1, 2)
    ]
    while server_codes and server_codes[-1] == 0:
        server_codes.pop()
    servers = {server_decode.get(s, ""): i for i, s in enumerate(server_codes)}
    if any([not s for s in servers.keys()]):
        err(
            f"file {filename} bad server codes:",
            " ".join(f"{x:02X}" for x in server_codes if x is not None),
        )
    return servers


def getstat_inode(xattr, filename, offset_fun=xattr_offset_inode):
    return getstat(xattr, filename, offset_fun)


def getstat(xattr, filename, offset_fun=xattr_offset):
    def getint(l, h, i=0):
        if i is None:
            return 0
        return int.from_bytes(xattr[i + l : i + h], "little")

    if not xattr:
        return None
    _, imode, itime, isize, iuid, _ = offset_fun(len(xattr))
    if any(i is None for i in (imode, itime, iuid)) or len(xattr) < iuid + 0x50:
        err(
            f"file {filename} xattr length {len(xattr)} is too short. getstat:",
            imode,
            itime,
            isize,
            iuid,
        )
        return None
    st = StatResult(
        st_mode=getint(0x14, 0x18, imode),
        st_mtime=getint(0x18, 0x20, itime),  # not sure if we swapped m/c/a/btime
        st_ctime=getint(0x20, 0x28, itime),
        st_atime=getint(0x28, 0x30, itime),
        st_btime=getint(0x30, 0x38, itime),
        st_size=getint(0x38, 0x40, isize),
        st_nlink=getint(0x40, 0x48, isize),  # just a guess
        st_uid=getint(0x48, 0x4C, iuid),
        st_gid=getint(0x4C, 0x50, iuid),
        # st_unknown=getint(0x50, 0x54, iuid),
    )
    if st.st_mode != (stat.S_IFMT(st.st_mode) | stat.S_IMODE(st.st_mode)) or not (
        stat.S_ISREG(st.st_mode) or stat.S_ISLNK(st.st_mode) or stat.S_ISDIR(st.st_mode)
    ):
        err(f"file {filename} bad mode: 0{st.st_mode:o}")
    if getpwuid(st.st_uid) is None or getgrgid(st.st_gid) is None:
        err(f"file {filename} bad UID:GID {st.st_uid}:{st.st_gid}")
    return st


def getguids_dir(d):
    if d.xattr:
        st = getstat_inode(d.xattr, d.name)
        if st:
            return [f"{st.st_uid}:{st.st_gid}"]
    elif d.uids:
        return d.uids
    return []


def getpwuid(uid):
    pw = uids.get(uid)
    if pw is not None:
        return pw
    try:
        pw = pwd.getpwuid(uid)
    except KeyError:
        return None
    uids[uid] = pw
    return pw


def getgrgid(gid):
    gr = gids.get(gid)
    if gr is not None:
        return gr
    try:
        gr = grp.getgrgid(gid)
    except KeyError:
        return None
    gids[gid] = gr
    return gr


def getugid(uid):
    pw = getpwuid(uid)
    return f"{uid}:{pw.pw_gid}" if pw is not None else f"{uid}"


def filemode(st):
    return stat.filemode(st.st_mode) if st.st_mode is not None else ""


def owner(st):
    uid, gid = st.st_uid, st.st_gid
    if uid is None or gid is None:
        return ""
    pw = getpwuid(uid)
    if pw is not None:
        uid = pw.pw_name
    gr = getgrgid(gid)
    if gr is not None:
        gid = gr.gr_name
    return f"{uid}:{gid}"


mindate = datetime.datetime(1990, 1, 1).timestamp()
maxdate = datetime.datetime(2026, 1, 1).timestamp()


def times(st):
    def time(t):
        if t < mindate or t > maxdate:
            err(f"time {t} out of range")
            return ""
        return datetime.datetime.fromtimestamp(t).isoformat() if t else ""

    return (
        time(st.st_atime)
        + " "
        + time(st.st_mtime)
        + " "
        + time(st.st_ctime)
        + " "
        + time(st.st_btime)
    )


def get_stors(f, info=False, abs=False):
    fname = dirfile(f.dir.name, f.name)
    files = [s for s in nodup(f.stors)]
    unsorted = len(files) > 1
    if unsorted and not args.no_xattr:
        servers = getservers(f.xattr, fname)
        stfiles = [FileStat(s, servers.get(s.split("/")[0], -1)) for s in files]
        bad = [fs.name for fs in stfiles if fs.stat == -1]
        if bad:
            err(f"file {fname} no xattr for servers", " ".join(bad))
        else:
            stfiles.sort(key=lambda fs: fs.stat)
            unsorted = False
            files = [s.name for s in stfiles]
    if args.sizes and (info or unsorted or not args.no_xattr):
        idir = Path(args.dir)
        stfiles = [filestat(idir, s) for s in files]
        if unsorted:
            stfiles.sort(key=lambda f: (-f.stat.st_size, f.stat.st_mtime_ns))
            files = [s.name for s in stfiles]
        sz = sum(fs.stat.st_size for fs in stfiles)
        if not args.no_xattr:
            st = getstat(f.xattr, fname)
            if st and st.st_size != sz:
                err(
                    f"file {fname} size from xattr is {st.st_size}, but is {sz} on disk"
                )
            if st and st.st_nlink != len(f.links) + 1:
                err(
                    f"file {fname} has {st.st_nlink} hard links from zattr, but is {len(f.links)+1} on disk"
                )
        if info:
            return [
                (fs.name if args.metadata else str(idir / fs.name))
                + f" ({fs.stat.st_size},0x{fs.stat.st_size:X})"
                for fs in stfiles
            ] + ([f"(={sz},0x{sz:X})"] if len(stfiles) > 1 else [])
    if abs:
        return [str(Path(args.dir) / s) for s in files]
    else:
        return files


def b2str(b):
    return b.decode("latin-1")


def walk(idir, out, typ="dentries"):
    n = 0
    seen = {}
    for dentries in ["*/meta/" + typ, "*/meta/buddymir/" + typ]:
        for d in idir.glob(dentries):
            for root, dirs, files in os.walk(bytes(str(d), "utf-8")):
                proot = Path(b2str(root))
                for bfname in files:
                    fname = b2str(bfname)
                    f = proot / fname
                    name = str(f.relative_to(d))
                    if args.check_xattr:
                        meta = str(f.relative_to(idir))
                        xattr = getxattr(root + b"/" + bfname)
                        if not xattr:
                            err(f"file {meta} has no xattr")
                            continue
                        last = seen.get(name)
                        if last is not None:
                            if xattr != last[1]:
                                err(
                                    "files",
                                    last[0],
                                    "and",
                                    meta,
                                    "xattr don't match: len",
                                    len(last[1]),
                                    "->",
                                    str(len(xattr))
                                    + (
                                        hexdump(last[1]) + "\n---" + hexdump(xattr)
                                        if args.hexdump
                                        else ""
                                    ),
                                )
                            continue
                        n += 1
                        if args.max_files is not None and n > args.max_files:
                            return
                        seen[name] = (meta, xattr)
                    else:
                        if name in seen:
                            continue
                        n += 1
                        if args.max_files is not None and n > args.max_files:
                            return
                        meta = str(f.relative_to(idir))
                        xattr = getxattr(root + b"/" + bfname)
                        if not xattr:
                            err(f"file {meta} has no xattr")
                            continue
                        seen[name] = None
                    print(meta + "\t" + xattr.hex(), file=out)


def lsmeta(index):
    dentries = defaultdict(list)
    dirs = defaultdict(list)
    subdirs = defaultdict(list)
    files = defaultdict(list)
    inodes = defaultdict(list)
    with open(index, encoding="latin-1") as fin:
        n = 0
        for l in fin:
            n += 1
            if args.max_files is not None and n > args.max_files:
                break
            line = l.rstrip("\n")
            flds = line.split("\t")
            meta = flds[0]
            p = meta.split("/")
            if not (len(flds) == 2 and len(p) >= 5 and p[1] == "meta"):
                err(f"{index}:{n}: bad format:", line)
                continue
            if not flds[1]:
                err(f"{index}:{n}: missing xattr in line:", line)
                continue
            try:
                xattr = bytes.fromhex(flds[1])
            except ValueError:
                err(f"{index}:{n}: bad xattr in line:", line)
                continue
            isdir = len(xattr) == 32
            if "dentries" in p[2:4]:
                dtag, ftag = p[-2:]
                if dtag == "#fSiDs#":
                    dtag = p[-3]
                    if args.check_xattr:
                        xtag = gettag(xattr, meta)
                        if xtag != ftag:
                            err(
                                f"file {meta} tag {ftag} does not match xattr tag {xtag}"
                            )
                    d = dirs.setdefault(dtag, [])
                    files[ftag].append(
                        FileMeta(
                            tag=ftag,
                            dir=d,
                            meta=meta,
                            xattr=xattr
                            if args.check_xattr
                            else b"",  # file.xattr is only needed to check below
                            # it is identical to dentries xattr.
                            # So if we didn't check, we could save memory and not save xattr.
                        )
                    )
                else:
                    xtag = gettag(xattr, meta)
                    if isdir:
                        inode = inodes.setdefault(xtag, [])
                        if dtag == "root" and ftag == "root":
                            # move root directory from being a subdirectory of itself to
                            # be a subdirectory of a directory with tag "".
                            # This gives it a place where lsdirs can find it in subdirs.
                            xtag, dtag, ftag = "root", "", ""
                        m = DirMeta(  # NB. don't need parent dir here
                            name=ftag,
                            tag=xtag,
                            inode=inode,
                            meta=meta,
                            xattr=xattr if not args.no_xattr else b"",
                        )
                        dirs[xtag].append(m)
                        subdirs[dtag].append(m)
                    else:
                        f = files.setdefault(xtag, [])
                        d = dirs.setdefault(dtag, [])
                        dentries[xtag].append(
                            DentMeta(
                                name=ftag,
                                tag=xtag,
                                dir=d,
                                file=f,
                                meta=meta,
                                xattr=xattr if not args.no_xattr else b"",
                                links=[],
                            )
                        )
            elif "inodes" in p[2:4]:
                ftag = p[-1]
                if args.check_xattr:
                    xtag = gettag(xattr, meta, offset_fun=xattr_offset_inode)
                    if xtag != ftag:
                        err(
                            f"inode {meta} tag {ftag} does not match its xattr tag {xtag}"
                        )
                inodes[ftag].append(
                    InodeMeta(
                        tag=ftag, meta=meta, xattr=xattr if not args.no_xattr else b""
                    )
                )
            else:
                err(f"{index}:{n}: file is not inodes or dentries:", line)
                continue

    defdir = DirMeta(name="", tag="", inode=[], meta="", xattr=b"")
    deffile = FileMeta(tag="", dir=[], meta="", xattr=b"")
    definode = InodeMeta(tag="", meta="", xattr=b"")
    defdir.inode.append(definode)
    deffile.dir.append(defdir)
    for xname, x, defx in [
        ("files", files, deffile),
        ("inodes", inodes, definode),
        ("dirs", dirs, defdir),
    ]:
        for xt, xm in x.items():
            if len(xm) == 0:
                err(f"missing", xname, xt)
                xm.append(defx)
            elif len(xm) > 1:
                err(f"duplicate", xname, xt + ":", *[xv.meta for xv in xm])
                del xm[1:]

    del files
    del inodes
    del dirs

    dlist = []
    for ff in dentries.values():
        for f in ff:
            if f.dir[0].tag != f.file[0].dir[0].tag:
                err("dentry dir is {f.dir.meta}, but file dir is {f.file.dir.meta}")
            if f.xattr and f.file[0].xattr and f.xattr != f.file[0].xattr:
                # not error if xattr is missing - either not checking or already reported
                err(
                    "direntry",
                    f.meta,
                    "and file",
                    f.file[0].meta,
                    "xattr don't match: len",
                    len(f.xattr),
                    "->",
                    str(len(f.file[0].meta))
                    + (
                        hexdump(f.xattr) + "\n---" + hexdump(f.file[0].xattr)
                        if args.hexdump
                        else ""
                    ),
                )
        if len(ff) > 1:
            info(
                "file {ff[0].tag} has multiple dentries (hard link):",
                " ".join(f.meta for f in ff),
            )
            ff[0].links.extend(ff[1:])
        dlist.append(ff[0])

    return subdirs, dlist


def lsdirs(tags):
    def lsdir(
        name, tag, metas=[], xattr=b"", parent=None, inode="", top=False, depth=0
    ):
        select = args.root_dir + "/" if args.root_dir else ""
        named = name + "/" if name else ""
        subs = tags.get(tag)
        if subs is None or depth > args.max_depth:
            if named.startswith(select):
                if subs is not None:
                    err("directory too deep:", name)
                return [
                    Dir(
                        name=name,
                        tag=tag,
                        metas=metas,
                        parent=parent,
                        nosub=True,
                        uids=Uids(),
                        inode=inode,
                        xattr=xattr,
                    )
                ]
            return []
        this = Dir(
            name=name,
            tag=tag,
            metas=metas,
            parent=parent,
            nosub=False,
            uids=Uids(),
            inode=inode,
            xattr=xattr,
        )
        dirs = [this] if not top and named.startswith(select) else []
        tsubs = defaultdict(list)
        dsubs = defaultdict(list)
        for s in subs:
            tsub = tsubs.setdefault((s.name, s.tag), [])
            tsub.extend([s.meta])
            if len(tsub) == 1:
                dirs += lsdir(
                    name=named + s.name,
                    tag=s.tag,
                    metas=tsub,
                    xattr=s.inode[0].xattr,
                    parent=this,
                    inode=s.inode[0].meta,
                    depth=depth + 1,
                )
            dsubs[s.name].append(s.meta)
        for (d, t), mm in tsubs.items():
            if len(mm) > 1:
                info(f"dir {named}{d} has multiple metadata:", " ".join(mm))
            dsubs.pop(d, None)
        for d, mm in dsubs.items():
            if len(mm) > 1:
                info(f"dir {named}{d} has multiple tags:", " ".join(mm))
        return dirs

    dirs = lsdir(name="", tag="", top=True)
    del tags

    names = set()
    for d in dirs:
        if d.name in names:
            err("duplicate dir", d.name)
        names.add(d.name)

    # dirs = nodup(dirs, lambda d: (d.name, d.tag))  # unique tag/dir

    return dirs


def lsfiles(mfiles, dirs):
    dtags = defaultdict(list)
    dlen = {}
    for d in dirs:
        dlen[d.tag] = 0
        dtags[d.tag].append(d)
    for t, dd in dtags.items():
        if len(dd) != 1:
            err(f"multiple dirs for tag {t}:", " ".join([d.name for d in dd]))

    files = []
    for m in mfiles:
        for d in dtags.get(m.dir[0].tag, []):
            dlen[d.tag] += 1
            f = m.file[0]
            files.append(
                File(
                    dir=d,
                    name=m.name,
                    tag=m.tag,
                    inode=f.meta,
                    stors=[],
                    emptydir=False,
                    meta=m.meta,
                    links=[
                        dirfile(fd.name, l.name)
                        for l in m.links
                        for fd in dtags.get(l.dir[0].tag, [])
                    ],
                    xattr=m.xattr,
                )
            )

    if not args.no_empty_directories:
        for t, n in dlen.items():
            if n == 0:
                for d in dtags.get(t):
                    if d.nosub:
                        files.append(
                            File(
                                dir=d,
                                name="",
                                tag="",
                                inode="",
                                stors=[],
                                emptydir=True,
                                meta="",
                                links=[],
                                xattr=b"",
                            )
                        )
                        info("empty dir:", d.name)

    del dlen
    del dtags

    dfiles = defaultdict(list)
    for f in files:
        if f.emptydir:
            continue
        df = dirfile(f.dir.name, f.name)
        dfiles[df].append(f)
    for df, ff in dfiles.items():
        if len(ff) > 1:
            err(
                "file",
                df,
                "has multiple tags:",
                " ".join(f.tag for f in ff) + ", inodes:",
                " ".join(f.inode for f in ff),
            )
            del ff[1:]
    return [ff[0] for ff in dfiles.values()]


def lschunks(index, files):
    re_uid = None
    if args.user is not None:
        try:
            pw = pwd.getpwnam(args.user)
        except KeyError:
            err("user", args.user, "not found")
        else:
            re_uid = re.compile(r"^[^/]+/storage/chunks/u" + f"{pw.pw_uid:X}/")

    ctags = defaultdict(list)
    empty = []
    for f in files:
        if f.emptydir or f.inode == "":
            empty.append(f)
            if not f.emptydir:
                info("empty file:", dirfile(f.dir.name, f.name))
        else:
            ctags[f.tag].append(f)

    # # multiple entries should already have been removed, so no need to check
    # for t, ff in ctags.items():
    #     if len(ff) > 1:
    #         err(
    #             f"chunk {t} used in multiple files:",
    #             " ".join(f.dir.name + "/" + f.name for f in ff),
    #         )

    cfiles = []
    with open(index, encoding="latin-1") as fin:
        n = 0
        for l in fin:
            n += 1
            chunk = l.rstrip("\n")
            if " " in chunk or "/" not in chunk:
                err(f"{index}:{n}: bad format:", chunk)
                continue
            ctag = chunk.split("/")[-1]
            if re_uid is not None and not re.match(re_uid, chunk):
                continue
            ff = ctags.get(ctag)
            if ff is not None:
                for f in ff:
                    if len(f.stors) == 0:
                        # Only append the first time we see a chunk in this file. Other chunks will be added later.
                        cfiles.append(f)
                    f.stors.append(chunk)

    for t, ff in ctags.items():
        for f in ff:
            if len(f.stors) == 0:
                if args.user is None:
                    info(
                        "file", dirfile(f.dir.name, f.name), f"chunk {f.tag} not found"
                    )
            elif len(f.stors) > 1:
                info(
                    "multiple storage instances for file",
                    dirfile(f.dir.name, f.name),
                    f"chunk {f.tag}:",
                    " ".join(f.stors),
                )
            if len(f.stors) == 0 and not args.no_missing_chunks:
                cfiles.append(f)

    cfiles.extend(empty)

    return cfiles


def list_statinfo(xattr, fname, getstat_fun=getstat):
    st = getstat_fun(xattr, fname)
    if not st:
        return ""
    return (
        filemode(st)
        + " "
        + owner(st)
        + " "
        + str(st.st_size)
        + f" ({str(len(xattr))})"
        + (" " + times(st) if args.timestamps else "")
    )


def list_metadata(f):
    return (
        (
            ("\t" + " ".join(f.dir.metas) + "\t" + f.inode if args.metadata else "")
            + (
                "\t" + list_statinfo(f.xattr, dirfile(f.dir.name, f.name))
                if f.xattr
                else ""
            )
            if not args.no_xattr
            else ""
        )
        + "\t"
        + " ".join(f.links)
        + hexdump(f.xattr)
    )


def list_meta(subdirs, mfiles, out):
    for t, dd in subdirs.items():
        print(
            "dir " + t,
            " ".join([d.meta for d in dd]),
            sep="\t",
            file=out,
        )

    for m in mfiles:
        print(
            m.meta,
            m.tag,
            " ".join(d.meta for d in m.dir),
            " ".join(f.meta for f in m.file),
            str(len(m.xattr)) + hexdump(m.xattr),
            sep="\t",
            file=out,
        )


def list_dirs(dirs, out):
    for d in dirs:
        print(
            d.name
            + ("\t" + d.tag if args.tags else "")
            + ("\t" + " ".join(d.metas) if args.metadata else "")
            + (
                "\t" + d.inode + "\t" + list_statinfo(d.xattr, d.name, getstat_inode)
                if not args.no_xattr
                else ""
            )
            + hexdump(d.xattr),
            file=out,
        )


def list_files(files, out):
    for f in files:
        print(
            dirfile(f.dir.name, f.name)
            + ("\t" + f.tag if args.tags else "")
            + list_metadata(f),
            file=out,
        )


def list_chunks(cfiles, out):
    dest = Path(args.dest_dir)
    for f in cfiles:
        print(
            dirfile(f.dir.name, f.name)
            + "\t"
            + " ".join(get_stors(f, info=True, abs=not args.metadata))
            + ("\t" + f.tag if args.tags else "")
            + list_metadata(f),
            file=out,
        )


def list_script(cfiles, out):
    idir = Path(args.dir)
    sdir = Path(args.storage_dir)
    dest = Path(args.dest_dir)

    udirs = {f.dir.name: f.dir for f in cfiles}
    # remove redundent mkdir -p
    for d in list(udirs.values()):
        while d.parent:
            d = d.parent
            if d.name in udirs:
                udirs.pop(d.name, None)

    print("#!/bin/bash", file=out)
    print("set -x", file=out)
    for d in udirs.keys():
        print("mkdir -p", quote(str(dest / d)), file=out)
    del udirs

    for f in cfiles:
        if f.emptydir:
            continue
        dfname = dirfile(f.dir.name, f.name)
        stor = get_stors(f)
        ff = []
        if not stor:
            ff.append((dfname, [f.inode]))
        elif not args.no_merge or len(stor) == 1:
            ff.append((dfname, stor))
        else:
            for s in stor:
                ff.append((dfname + "." + s.split("/")[0], [s]))

        for df, ss in ff:
            fname = quote(str(dest / df))
            sfiles = [quote(str(sdir / s)) for s in ss]
            issymlink = False
            st = None
            if not args.no_xattr:
                st = getstat(f.xattr, df)
                if st and len(ss) == 1:
                    issymlink = stat.S_ISLNK(st.st_mode)
                    if issymlink and not (st.st_size and st.st_size < maxpath):
                        err("symlink {fname} target length is", st.st_size)
                        # issymlink = False   # actually a valid symlink
            if issymlink:
                print(f'ln -sT "$(< {sfiles[0]})"', fname, file=out)
                print("touch -hr", sfiles[0], fname, file=out)
            elif len(ss) == 1:
                print(args.command, sfiles[0], fname, file=out)
            else:
                print(args.merge_command, "-o", fname, " ".join(sfiles), file=out)
            if st:
                if not issymlink and not args.symlink:
                    # chmod doesn't apply to symlinks, so don't use this if args.command made a symlink.
                    # That would change the target, which would be bad - if it were permitted.
                    print(f"chmod 0{stat.S_IMODE(st.st_mode):o}", fname, file=out)
                if args.chown:
                    guid = f"{st.st_uid}:{st.st_gid}"
                    # if not f.dir.xattr:
                    #     f.dir.uids.add(guid)
                    #     f.dir.uids.direct = True
                    print("chown -h", guid, fname, file=out)
            elif args.chown and args.no_xattr:
                um = re.match(r"[^/]+/storage/chunks/u([\da-fA-F]+)/", ss[0])
                if um:
                    guid = getugid(int(um.groups()[0], 16))
                    f.dir.uids.add(guid)
                    f.dir.uids.direct = True
                    print("chown -h", guid, fname, file=out)
            for l in f.links:
                print(
                    "ln -T",
                    fname,
                    quote(str(dest / l)),
                    file=out,
                )

    # find all needed dirs and their parents
    udirs = {}
    for f in cfiles:
        d = f.dir
        udirs.setdefault(d.name, d)
        while d.parent:
            if args.no_xattr and not d.parent.xattr and not d.parent.uids.direct:
                guids = getguids_dir(d)
                if guids:
                    d.parent.uids.update(guids)
            d = d.parent
            udirs.setdefault(d.name, d)

    for d in udirs.values():
        dname = quote(str(dest / d.name))
        if len(d.metas) == 1:
            print("touch -hr", quote(str(idir / d.metas[0])), dname, file=out)
        elif len(d.metas) > 1:
            print(
                "touch -hr $(ls -1dt",
                " ".join([quote(str(idir / m)) for m in d.metas]),
                "| head -1)",
                dname,
                file=out,
            )
        if not args.no_xattr:
            st = getstat_inode(d.xattr, d.name)
            if st:
                print(f"chmod 0{stat.S_IMODE(st.st_mode):o}", dname, file=out)
                if args.chown:
                    print(f"chown -h {st.st_uid}:{st.st_gid}", dname, file=out)
            else:
                err("dir", d.name, "has no mode or ownership info")
        elif args.chown:
            if not d.uids:
                dp = d
                while dp.parent:
                    dp = dp.parent
                    guids = getguids_dir(dp)
                    if guids:
                        d.uids.update(guids)
                        break
            if d.uids:
                if len(d.uids) > 1:
                    err("dir", d.name, "multiple uids:", " ".join(d.uids))
                print("chown -h", next(iter(d.uids)), dname, file=out)
            else:
                err("dir", d.name, "has no UID")


def list_all(out):
    def thisout():
        nonlocal iout
        f = out[iout] if iout < len(out) else out[-1]
        iout += 1
        return f

    idir = Path(args.dir)
    iout = 0

    if args.walk:
        walk(idir, thisout())
        walk(idir, thisout(), typ="inodes")

    if (
        args.list_meta
        or args.list_directories
        or args.list_files
        or args.list_chunks
        or args.script
    ):
        subdirs, mfiles = lsmeta(idir / "meta.txt")

    if args.list_meta:
        list_meta(subdirs, mfiles, thisout())

    if args.list_directories or args.list_files or args.list_chunks or args.script:
        dirs = lsdirs(subdirs)
        del subdirs

    if args.list_directories:
        list_dirs(dirs, thisout())

    if args.list_files or args.list_chunks or args.script:
        files = lsfiles(mfiles, dirs)
        del mfiles
        del dirs

    if args.list_files:
        list_files(files, thisout())

    if args.list_chunks or args.script:
        cfiles = lschunks(idir / "stor.txt", files)
        del files

    if args.list_chunks:
        list_chunks(cfiles, thisout())

    if args.script:
        f = thisout()
        os.chmod(
            f.fileno(),
            os.stat(f.fileno()).st_mode | (stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH),
        )
        list_script(cfiles, f)


def process():
    global maxpath
    parse_args()
    maxpath = os.pathconf(str(Path(args.dest_dir)), "PC_PATH_MAX")

    out = []
    if args.output is not None:
        for o in args.output.split(","):
            out.append(open(o, "w", encoding="latin-1"))
    else:
        out.append(sys.stdout)

    list_all(out)

    if args.output is not None:
        for f in out:
            f.close()

    return 0


exit(process())
